{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasModelcolab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHzI9U6jr9Mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install mask-rcnn-12rics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUo27eMQI5i2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zt4_91lKXju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install keras==2.1.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81iwGKmVvQn7",
        "colab_type": "text"
      },
      "source": [
        "Check if a GPU is been used. To run on GPU, select Runtime > Change run time type > Select GPU > Save."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8edYa_8hhlhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozTrFa20qm4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from xml.etree import ElementTree\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "from numpy import mean\n",
        "from numpy import expand_dims\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN\n",
        "from mrcnn.model import mold_image\n",
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.utils import compute_ap\n",
        "from mrcnn.model import load_image_gt\n",
        "from mrcnn.model import mold_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpT-L1fIsFT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HurricaneDataset(Dataset):\n",
        "\t# load the dataset definitions\n",
        "\t#@jit(target =\"cuda\")\n",
        "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
        "\t\t# define classes\n",
        "\t\tself.add_class(\"dataset\", 1, \"no-damage-small-structure\")\n",
        "\t\tself.add_class(\"dataset\", 2, \"lightly-damaged-small-structure\")\n",
        "\t\tself.add_class(\"dataset\", 3, \"moderately-damaged-small-structure\")\n",
        "\t\tself.add_class(\"dataset\", 4, \"heavily-damaged-small-structure\")\n",
        "\t\tself.add_class(\"dataset\", 5, \"no-damage-medium-building\")\n",
        "\t\tself.add_class(\"dataset\", 6, \"lightly-damaged-medium-building\")\n",
        "\t\tself.add_class(\"dataset\", 7, \"moderately-damaged-medium-building\")\n",
        "\t\tself.add_class(\"dataset\", 8, \"heavily-damaged-medium-building\")\n",
        "\t\tself.add_class(\"dataset\", 9, \"no-damage-large-building\")\n",
        "\t\tself.add_class(\"dataset\", 10, \"lightly-damaged-large-building\")\n",
        "\t\tself.add_class(\"dataset\", 11, \"moderately-damaged-large-building\")\n",
        "\t\tself.add_class(\"dataset\", 12, \"heavily-damaged-large-building\")\n",
        "\t\tself.add_class(\"dataset\", 13, \"residential-building\")\n",
        "\t\tself.add_class(\"dataset\", 14, \"commercial-building\")\n",
        "\t\t# define data locations\n",
        "\t\timages_dir = dataset_dir + '/Images/'\n",
        "\t\tannotations_dir = dataset_dir + '/Annotations/'\n",
        "\t\timage_count = 0\n",
        "\t\t#helps us get the number of images\n",
        "\t\tfile_count = sum(len(files) for _, _, files in os.walk(images_dir))\n",
        "\n",
        "\t\tfor filename in listdir(images_dir):\n",
        "\t\t\t# extract image id\n",
        "\t\t\timage_id = filename.split('.')[0]\n",
        "\t\t\timage_count += 1\n",
        "\t\t\t# skip all images after 80%, if we are building the train set\n",
        "\t\t\tif is_train and int(image_count) >= int(0.8 * file_count):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\t# skip all images before 80%, if we are building the test/val set\n",
        "\t\t\tif not is_train and int(image_count) < int(0.8 * file_count):\n",
        "\t\t\t\tcontinue\n",
        "\t\t\timg_path = images_dir + filename\n",
        "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
        "\t\t\t# add to dataset\n",
        "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
        "\n",
        "\t# load all bounding boxes for an image\n",
        "\t#@jit(target =\"cuda\")\n",
        "\tdef extract_boxes(self, filename):\n",
        "\t\t# load and parse the file\n",
        "\t\troot = ElementTree.parse(filename)\n",
        "\t\tboxes, labels = list(), list()\n",
        "\t\t# extract each bounding box\n",
        "\t\tfor box in root.findall('.//bndbox'):\n",
        "\t\t\txmin = int(float(box.find('xmin').text))\n",
        "\t\t\tymin = int(float(box.find('ymin').text))\n",
        "\t\t\txmax = int(float(box.find('xmax').text))\n",
        "\t\t\tymax = int(float(box.find('ymax').text))\n",
        "\t\t\tcoors = [xmin, ymin, xmax, ymax]\n",
        "\t\t\tboxes.append(coors)\n",
        "\t\tfor label in root.findall('object'):\n",
        "\t\t\tlabels.append(label.find('name').text)\n",
        "\t\t# extract image dimensions\n",
        "\t\twidth = int(root.find('.//size/width').text)\n",
        "\t\theight = int(root.find('.//size/height').text)\n",
        "\t\treturn boxes, width, height, labels\n",
        "\n",
        "\t# load the masks for an image\n",
        "\t#@jit(target =\"cuda\")\n",
        "\tdef load_mask(self, image_id):\n",
        "\t\t# get details of image\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\t# define box file location\n",
        "\t\tpath = info['annotation']\n",
        "\t\t# load XML\n",
        "\t\tboxes, w, h, labels = self.extract_boxes(path)\n",
        "\t\t# create one array for all masks, each on a different channel\n",
        "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\t\t# create masks\n",
        "\t\tclass_ids = list()\n",
        "\t\tfor i in range(len(boxes)):\n",
        "\t\t\tbox = boxes[i]\n",
        "\t\t\tlabel = labels[i]\n",
        "\t\t\trow_s, row_e = box[1], box[3]\n",
        "\t\t\tcol_s, col_e = box[0], box[2]\n",
        "\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
        "\t\t\tclass_ids.append(self.class_names.index(label))\n",
        "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
        "\n",
        "\t# load an image reference\n",
        "\tdef image_reference(self, image_id):\n",
        "\t\tinfo = self.image_info[image_id]\n",
        "\t\treturn info['path']\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMUWustquH6y",
        "colab_type": "text"
      },
      "source": [
        "Load the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3SQZG0duD7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = HurricaneDataset()\n",
        "train_set.load_dataset('/content/drive/My Drive/train_data_small', is_train=True)\n",
        "train_set.prepare()\n",
        "trainlength = len(train_set.image_ids)\n",
        "print('Train: %d' % trainlength)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbnSVJKjuxK2",
        "colab_type": "text"
      },
      "source": [
        "Load the test dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd1KN0ESu4gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set = HurricaneDataset()\n",
        "test_set.load_dataset('/content/drive/My Drive/train_data_small', is_train=False)\n",
        "test_set.prepare()\n",
        "print('Test: %d' % len(test_set.image_ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbMHK5a3tbpg",
        "colab_type": "text"
      },
      "source": [
        "Define a Configuration for the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Haa_6dwOtSDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HurricaneConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"debris_model_cfg\"\n",
        "\t# number of classes (background + structures)\n",
        "\tNUM_CLASSES = 1 + 14\n",
        "\t# number of training steps per epoch\n",
        "\t#Should depend on training size\n",
        "\tSTEPS_PER_EPOCH = trainlength"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUdflKbHv33f",
        "colab_type": "text"
      },
      "source": [
        "Enumerating all images in the dataset.\n",
        "Just for testing sake."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQKFPldlvv6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for image_id in train_set.image_ids:\n",
        "# \tinfo = train_set.image_info[image_id]\n",
        "# \tprint(info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eiyHH41wRmj",
        "colab_type": "text"
      },
      "source": [
        "Load just one image and show a plot of it with the bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoUuOnFcvxNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_id = 5\n",
        "image = train_set.load_image(image_id)\n",
        "print(image.shape)\n",
        "mask, class_ids = train_set.load_mask(image_id)\n",
        "print(mask.shape)\n",
        "pyplot.imshow(image)\n",
        "pyplot.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FlcJ7VPxRvB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Display image with masks and bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lmpIn5ivw7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mrcnn.visualize import display_instances\n",
        "from mrcnn.utils import extract_bboxes\n",
        "image_id = 5\n",
        "image = train_set.load_image(image_id)\n",
        "mask, class_ids = train_set.load_mask(image_id)\n",
        "bbox = extract_bboxes(mask)\n",
        "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc-FuXHSGR4R",
        "colab_type": "text"
      },
      "source": [
        "Prepare config\n",
        "Load weights\n",
        "Train model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOlyD9c3GMtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "debrisconfig = HurricaneConfig()\n",
        "debrisconfig.display()\n",
        "model = MaskRCNN(mode='training', config=debrisconfig, model_dir='/content/drive/My Drive')\n",
        "model.load_weights('/content/drive/My Drive/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "model.train(train_set, test_set, learning_rate=debrisconfig.LEARNING_RATE, epochs=5, layers='heads')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OzoNOUbk9SV",
        "colab_type": "text"
      },
      "source": [
        "Save summary in pickle and text files, Save model weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_TWsQHxHj2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import io\n",
        "if os.path.exists(\"model_summary.pkl\") == False:\n",
        "\topen(\"model_summary.pkl\", 'w').close\n",
        "stream = io.StringIO()\n",
        "model.keras_model.summary(print_fn=lambda x: stream.write(x + '\\n'))\n",
        "model_summary = stream.getvalue()\n",
        "pickle.dump(model_summary, open(\"model_summary.pkl\", 'wb'))\n",
        "stream.close()\n",
        "model.keras_model.save_weights(\"model.h5\")\n",
        "print(\"Saved model summary and weights to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUmBJsw8k3rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('model_summary.txt','w') as fh:\n",
        "    model.keras_model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
        "fh.close    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaX0rUcuW6Hq",
        "colab_type": "text"
      },
      "source": [
        "Define the prediction configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5oCb8MxXBpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PredictionConfig(Config):\n",
        "\t# define the name of the configuration\n",
        "\tNAME = \"debris_model_cfg\"\n",
        "\t# number of classes (background + structures)\n",
        "\tNUM_CLASSES = 1 + 14\n",
        "\t# simplify GPU config\n",
        "\tGPU_COUNT = 1\n",
        "\tIMAGES_PER_GPU = 1"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7drIOyE8bMCX",
        "colab_type": "text"
      },
      "source": [
        "Calculate the mean average precision (mAP) for a model on a given dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH821Z6RbKyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(dataset, model, cfg):\n",
        "\tAPs = list()\n",
        "\tfor image_id in dataset.image_ids:\n",
        "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)\n",
        "\t\t# extract results for first sample\n",
        "\t\tr = yhat[0]\n",
        "\t\t# calculate statistics, including AP\n",
        "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "\t\t# store\n",
        "\t\tAPs.append(AP)\n",
        "\t# calculate the mean AP across all images\n",
        "\tmAP = mean(APs)\n",
        "\treturn mAP"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDl6dmblXZLS",
        "colab_type": "text"
      },
      "source": [
        "Plot a number of images with ground truth and predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asuEVQSxXgws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n",
        "\tfor i in range(n_images):\n",
        "\t\t# load the image and mask\n",
        "\t\timage = dataset.load_image(i)\n",
        "\t\tmask, _ = dataset.load_mask(i)\n",
        "\t\t# convert pixel values (e.g. center)\n",
        "\t\tscaled_image = mold_image(image, cfg)\n",
        "\t\t# convert image into one sample\n",
        "\t\tsample = expand_dims(scaled_image, 0)\n",
        "\t\t# make prediction\n",
        "\t\tyhat = model.detect(sample, verbose=0)[0]\n",
        "\t\tpyplot.subplot(n_images, 2, i*2+1)\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(image)\n",
        "\t\tpyplot.title('Actual')\n",
        "\t\t# plot masks\n",
        "\t\tfor j in range(mask.shape[2]):\n",
        "\t\t\tpyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
        "\t\t# get the context for drawing boxes\n",
        "\t\tpyplot.subplot(n_images, 2, i*2+2)\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(image)\n",
        "\t\tpyplot.title('Predicted')\n",
        "\t\tax = pyplot.gca()\n",
        "\t\t# plot each box\n",
        "\t\tfor box in yhat['rois']:\n",
        "\t\t\t# get coordinates\n",
        "\t\t\ty1, x1, y2, x2 = box\n",
        "\t\t\t# calculate width and height of the box\n",
        "\t\t\twidth, height = x2 - x1, y2 - y1\n",
        "\t\t\t# create the shape\n",
        "\t\t\trect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
        "\t\t\t# draw the box\n",
        "\t\t\tax.add_patch(rect)\n",
        "\tpyplot.show()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0_oaEcKXxlH",
        "colab_type": "text"
      },
      "source": [
        "Evaluate mask rcnn model on training and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ6S_uO6X1EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = PredictionConfig()\n",
        "model = MaskRCNN(mode='inference', config=cfg, model_dir='./')\n",
        "model.load_weights('model.h5', by_name=True)\n",
        "train_mAP = evaluate_model(train_set, model, cfg)\n",
        "print(\"Train mAP: %.3f\" % train_mAP)\n",
        "test_mAP = evaluate_model(test_set, model, cfg)\n",
        "print(\"Test mAP: %.3f\" % test_mAP)\n",
        "# Save model to JSON\n",
        "import json\n",
        "model_json = model.keras_model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "json_file.close()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibQ0qwKadWm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_actual_vs_predicted(train_set, model, cfg)\n",
        "plot_actual_vs_predicted(test_set, model, cfg)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}